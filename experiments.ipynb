{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training, validation and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_helper import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] data/label: 12744/12744\n",
      "[Validation] data/label: 2248/2248\n",
      "[Test] data/label: 6388/6388\n"
     ]
    }
   ],
   "source": [
    "IMAGE_FOLDER_PATH = 'dataset/resized/frames/'\n",
    "LABEL_FOLDER_PATH = 'dataset/labels/'\n",
    "\n",
    "train_image_paths, train_labels, val_image_paths, val_labels, test_image_paths, test_labels = \\\n",
    "    load_dataset(image_folder_path=IMAGE_FOLDER_PATH,\n",
    "                 label_folder_path=LABEL_FOLDER_PATH,\n",
    "                 label_type='obj', hand_types=['left', 'right'],\n",
    "                 validation_split_ratio=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tensorflow to build computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "import vgg_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRETRAINED_VGG_MODEL_PATH = 'model/vgg_16.ckpt'\n",
    "MODEL_PATH = 'model/baseline_finetuned_vgg_16.ckpt'\n",
    "\n",
    "num_classes = 24\n",
    "batch_size = 32\n",
    "num_workers = 20\n",
    "max_epochs1 = 20\n",
    "max_epochs2 = 20\n",
    "max_patience = 3 # For early stopping\n",
    "learning_rate1 = 1e-3\n",
    "learning_rate2 = 1e-5\n",
    "dropout_keep_prob = 0.5\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 s, sys: 3.86 ms, total: 1.83 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def dataset_map_fn(image_path, label, is_training):\n",
    "    # Load image\n",
    "    image_string = tf.read_file(image_path)\n",
    "    image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    # Preprocess image\n",
    "    preprocessed_image = tf.cond(is_training,\n",
    "                                 true_fn=lambda: vgg_preprocessing.preprocess_image(image, 224, 224, is_training=True),\n",
    "                                 false_fn=lambda: vgg_preprocessing.preprocess_image(image, 224, 224, is_training=False))\n",
    "    return preprocessed_image, label\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Indicates whether we are in training or in test mode\n",
    "    # Since VGG16 has applied `dropout`, we need to disable it when testing.\n",
    "    is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n",
    "    \n",
    "    # Training, validation, testing data to feed in.\n",
    "    image_paths = tf.placeholder(dtype=tf.string, shape=(None,), name='image_paths')\n",
    "    labels = tf.placeholder(dtype=tf.int32, shape=(None,), name='labels')\n",
    "    \n",
    "    # Use dataset API to automatically generate batch data by iterator.\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(lambda image_path, label: dataset_map_fn(image_path, label, is_training))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    batched_dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    # Now we define an iterator that can operator on dataset.\n",
    "    # The iterator can be reinitialized by calling:\n",
    "    # sess.run(dataset_init_op, feed_dict={image_paths=train_image_paths, labels=train_labels}) \n",
    "    # for 1 epoch on the training set.\n",
    "    \n",
    "    # Once this is done, we don't need to feed any value for images and labels\n",
    "    # as they are automatically pulled out from the iterator queues.\n",
    "\n",
    "    # A reinitializable iterator is defined by its structure. We could use the\n",
    "    # `output_types` and `output_shapes` properties of dataset.\n",
    "    # The dataset will be fed with training, validation or testing data.\n",
    "    iterator = tf.contrib.data.Iterator.from_structure(batched_dataset.output_types,\n",
    "                                                       batched_dataset.output_shapes)\n",
    "    \n",
    "    # A batch of data to feed into the networks.\n",
    "    batch_images, batch_labels = iterator.get_next()\n",
    "    dataset_init_op = iterator.make_initializer(batched_dataset)\n",
    "    \n",
    "    # ---------------------------------------------------------------------\n",
    "    # Now that we have set up the data, it's time to set up the model.\n",
    "    # For this example, we'll use VGG-16 pretrained on ImageNet. We will remove the\n",
    "    # last fully connected layer (fc8) and replace it with our own, with an\n",
    "    # output size `num_classes`\n",
    "    # We will first train the last layer for a few epochs.\n",
    "    # Then we will train the entire model on our dataset for a few epochs.\n",
    "\n",
    "    # Get the pretrained model, specifying the num_classes argument to create a new\n",
    "    # fully connected replacing the last one, called \"vgg_16/fc8\"\n",
    "    # Each model has a different architecture, so \"vgg_16/fc8\" will change in another model.\n",
    "    # Here, logits gives us directly the predicted scores we wanted from the images.\n",
    "    # We pass a scope to initialize \"vgg_16/fc8\" weights with he_initializer\n",
    "    vgg = tf.contrib.slim.nets.vgg\n",
    "    with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=weight_decay)):\n",
    "        logits, _ = vgg.vgg_16(batch_images, num_classes=num_classes, is_training=is_training,\n",
    "                               dropout_keep_prob=dropout_keep_prob)\n",
    "    \n",
    "    # Restore only the layers up to fc7 (included)\n",
    "    # Calling function `init_fn(sess)` will load all the pretrained weights.\n",
    "    variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "    init_fn = tf.contrib.framework.assign_from_checkpoint_fn(PRETRAINED_VGG_MODEL_PATH, variables_to_restore)\n",
    "\n",
    "    # Initialization operation from scratch for the new \"fc8\" layers\n",
    "    # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "    fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "    fc8_init = tf.variables_initializer(fc8_variables)\n",
    "    \n",
    "    # ---------------------------------------------------------------------\n",
    "    # Using tf.losses, any loss is added to the tf.GraphKeys.LOSSES collection\n",
    "    # We can then call the total loss easily\n",
    "    tf.losses.sparse_softmax_cross_entropy(labels=batch_labels, logits=logits)\n",
    "    loss = tf.losses.get_total_loss()\n",
    "    \n",
    "    # First we want to train only the reinitialized last layer fc8 for a few epochs.\n",
    "    # We run minimize the loss only with respect to the fc8 variables (weight and bias).\n",
    "    fc8_optimizer = tf.train.GradientDescentOptimizer(learning_rate1)\n",
    "    fc8_train_op = fc8_optimizer.minimize(loss, var_list=fc8_variables)\n",
    "    \n",
    "    # Then we want to finetune the entire model for a few epochs.\n",
    "    # We run minimize the loss only with respect to all the variables.\n",
    "    full_optimizer = tf.train.GradientDescentOptimizer(learning_rate2)\n",
    "    full_train_op = full_optimizer.minimize(loss)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    prediction = tf.to_int32(tf.argmax(logits, 1))\n",
    "    correct_prediction = tf.equal(prediction, batch_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "    \n",
    "    # 'Saver' op to save and restore all the variables\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sess, loss, correct_prediction, dataset_init_op, feed_dict):\n",
    "    \"\"\"\n",
    "        Evaluation in training loop.\n",
    "        Check the performance of the model on either train, val or test (depending on `dataset_init_op`)\n",
    "        Note: The arguments are tensorflow operators defined in the graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the correct dataset.\n",
    "    sess.run(dataset_init_op, feed_dict=feed_dict)\n",
    "\n",
    "    data_loss = 0\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    # Evaluate on every batch.\n",
    "    while True:\n",
    "        try:\n",
    "            # Disable `is_training` since we have `dropout` in VGG net.\n",
    "            _loss, _correct_prediction = sess.run([loss, correct_prediction], feed_dict={is_training: False})\n",
    "\n",
    "            data_loss += _loss\n",
    "            num_correct += _correct_prediction.sum() # e.g: [True, False, True].sum() = 2\n",
    "            num_samples += _correct_prediction.shape[0] # Batch size\n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    data_loss = data_loss / num_samples\n",
    "    acc = num_correct / num_samples\n",
    "\n",
    "    return data_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Now that we have built the graph and finalized it, we define the session.\n",
    "# The session is the interface to *run* the computational graph.\n",
    "# We can call our training operations with `sess.run(train_op)` for instance\n",
    "sess = tf.Session(graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/baseline_finetuned_vgg_16.ckpt\n"
     ]
    }
   ],
   "source": [
    "# init_fn(sess) # load the pretrained weights\n",
    "# sess.run(fc8_init)  # initialize the new fc8 layer\n",
    "\n",
    "saver.restore(sess, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_acc = 0.0\n",
    "patience = 0\n",
    "\n",
    "# Update only the last layer for a few epochs.\n",
    "for epoch in tqdm(range(max_epochs1)):\n",
    "    # Run an epoch over the training data.\n",
    "    print('-'*110)\n",
    "    print('Starting epoch {}/{}'.format(epoch+1, max_epochs1))\n",
    "    # Here we initialize the iterator with the training set.\n",
    "    # This means that we can go through an entire epoch until the iterator becomes empty.\n",
    "    sess.run(dataset_init_op, feed_dict={image_paths: train_image_paths,\n",
    "                                         labels: train_labels,\n",
    "                                         is_training: True})\n",
    "    while True:\n",
    "        try:\n",
    "            _ = sess.run(fc8_train_op, feed_dict={is_training: True})\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    # Check performance every epoch\n",
    "    train_loss, train_acc = evaluate(sess, loss, correct_prediction, dataset_init_op,\n",
    "                                     feed_dict={image_paths: train_image_paths,\n",
    "                                                labels: train_labels,\n",
    "                                                is_training: True})\n",
    "    \n",
    "    val_loss, val_acc = evaluate(sess, loss, correct_prediction, dataset_init_op,\n",
    "                                 feed_dict={image_paths: val_image_paths,\n",
    "                                            labels: val_labels,\n",
    "                                            is_training: False})\n",
    "    \n",
    "    print('[Train] loss: {} | accuracy: {}'.format(train_loss, train_acc))\n",
    "    print('[Validation] loss: {} | accuracy: {}'.format(val_loss, val_acc))\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if val_acc > max_acc:\n",
    "        patience = 0\n",
    "        max_acc = val_acc\n",
    "        save_path = saver.save(sess, MODEL_PATH)\n",
    "        print(\"Model updated and saved in file: %s\" % save_path)\n",
    "    else:\n",
    "        patience += 1\n",
    "        print('Model not improved at epoch {}/{}. Patience: {}/{}'.format(epoch+1, max_epochs1, patience, max_patience))\n",
    "    # Early stopping.\n",
    "    if patience > max_patience:\n",
    "        print('Max patience exceeded. Early stopping.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 1/20\n",
      "[Train] loss: 0.06555639462731427 | accuracy: 0.5750156936597615\n",
      "[Validation] loss: 0.0848904012361031 | accuracy: 0.40346975088967973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [07:34<2:23:48, 454.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 2/20\n",
      "[Train] loss: 0.06447075263404727 | accuracy: 0.573210922787194\n",
      "[Validation] loss: 0.084733720669967 | accuracy: 0.40791814946619215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [14:56<2:15:08, 450.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [22:14<2:06:34, 446.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.06353195551350217 | accuracy: 0.5796453232893911\n",
      "[Validation] loss: 0.08429824526411783 | accuracy: 0.40569395017793597\n",
      "Model not improved at epoch 3/20. Patience: 1/3\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [29:32<1:58:26, 444.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.06272306610822528 | accuracy: 0.5895323289391086\n",
      "[Validation] loss: 0.08507471343376459 | accuracy: 0.4052491103202847\n",
      "Model not improved at epoch 4/20. Patience: 2/3\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 5/20\n",
      "[Train] loss: 0.062337400530840865 | accuracy: 0.5901600753295668\n",
      "[Validation] loss: 0.08492594957351685 | accuracy: 0.4101423487544484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [36:55<1:50:57, 443.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 6/20\n",
      "[Train] loss: 0.06179060026002394 | accuracy: 0.6022441933458883\n",
      "[Validation] loss: 0.08481581068972252 | accuracy: 0.4141459074733096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [44:17<1:43:26, 443.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [51:35<1:35:41, 441.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.06140911059976747 | accuracy: 0.6039704959196485\n",
      "[Validation] loss: 0.08433783902816501 | accuracy: 0.41370106761565834\n",
      "Model not improved at epoch 7/20. Patience: 1/3\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 8/20\n",
      "[Train] loss: 0.060821566531961996 | accuracy: 0.6117388575015693\n",
      "[Validation] loss: 0.0838436194798276 | accuracy: 0.4150355871886121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [58:57<1:28:23, 441.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 9/20\n",
      "[Train] loss: 0.06090236760615105 | accuracy: 0.6097771500313873\n",
      "[Validation] loss: 0.08385337905103202 | accuracy: 0.41725978647686834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [1:06:19<1:21:00, 441.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [1:13:38<1:13:29, 440.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.0604331734995384 | accuracy: 0.6060891399874451\n",
      "[Validation] loss: 0.08345580164648035 | accuracy: 0.41725978647686834\n",
      "Model not improved at epoch 10/20. Patience: 1/3\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 11/20\n",
      "[Train] loss: 0.0601483986988355 | accuracy: 0.6109541745134965\n",
      "[Validation] loss: 0.08394713620274093 | accuracy: 0.4194839857651246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [1:21:00<1:06:12, 441.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 12/20\n",
      "[Train] loss: 0.05930059250240721 | accuracy: 0.6227244193345888\n",
      "[Validation] loss: 0.08404795406551972 | accuracy: 0.4225978647686833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [1:28:23<58:55, 441.91s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 13/20\n",
      "[Train] loss: 0.059391583941002274 | accuracy: 0.6164469554300063\n",
      "[Validation] loss: 0.08370742005597655 | accuracy: 0.42437722419928825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [1:35:47<51:36, 442.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 14/20\n",
      "[Train] loss: 0.05874749435356257 | accuracy: 0.6242937853107344\n",
      "[Validation] loss: 0.0832487836851344 | accuracy: 0.42526690391459077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [1:43:09<44:13, 442.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 15/20\n",
      "[Train] loss: 0.058546627795105076 | accuracy: 0.6282172002510985\n",
      "[Validation] loss: 0.08318454005964286 | accuracy: 0.42571174377224197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [1:50:32<36:52, 442.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 16/20\n",
      "[Train] loss: 0.05854674014780256 | accuracy: 0.6226459510357816\n",
      "[Validation] loss: 0.08299339968326677 | accuracy: 0.4279359430604982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [1:57:55<29:30, 442.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [2:05:14<22:04, 441.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.05788087738211321 | accuracy: 0.632532956685499\n",
      "[Validation] loss: 0.08335444681160815 | accuracy: 0.4261565836298932\n",
      "Model not improved at epoch 17/20. Patience: 1/3\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [2:12:33<14:41, 440.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.05768772804430275 | accuracy: 0.6344946641556811\n",
      "[Validation] loss: 0.08321665688765854 | accuracy: 0.42571174377224197\n",
      "Model not improved at epoch 18/20. Patience: 2/3\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 19/20\n",
      "[Train] loss: 0.05733292395972787 | accuracy: 0.638653483992467\n",
      "[Validation] loss: 0.08300913652915547 | accuracy: 0.4288256227758007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [2:19:54<07:21, 441.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model updated and saved in file: model/baseline_finetuned_vgg_16.ckpt\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Starting epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [2:27:13<00:00, 440.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss: 0.05706142638362734 | accuracy: 0.6359855618330195\n",
      "[Validation] loss: 0.08303350178372393 | accuracy: 0.4288256227758007\n",
      "Model not improved at epoch 20/20. Patience: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the entire model for a few more epochs, continuing with the *same* weights.\n",
    "max_acc = 0.0\n",
    "patience = 0\n",
    "for epoch in tqdm(range(max_epochs2)):\n",
    "    # Run an epoch over the training data.\n",
    "    print('-'*110)\n",
    "    print('Starting epoch {}/{}'.format(epoch+1, max_epochs2))\n",
    "    # Here we initialize the iterator with the training set.\n",
    "    # This means that we can go through an entire epoch until the iterator becomes empty.\n",
    "    sess.run(dataset_init_op, feed_dict={image_paths: train_image_paths,\n",
    "                                         labels: train_labels,\n",
    "                                         is_training: True})\n",
    "    while True:\n",
    "        try:\n",
    "            _ = sess.run(full_train_op, feed_dict={is_training: True})    \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    # Check performance every epoch\n",
    "    train_loss, train_acc = evaluate(sess, loss, correct_prediction, dataset_init_op,\n",
    "                                     feed_dict={image_paths: train_image_paths,\n",
    "                                                labels: train_labels,\n",
    "                                                is_training: True})\n",
    "    \n",
    "    val_loss, val_acc = evaluate(sess, loss, correct_prediction, dataset_init_op,\n",
    "                                 feed_dict={image_paths: val_image_paths,\n",
    "                                            labels: val_labels,\n",
    "                                            is_training: False})\n",
    "    \n",
    "    print('[Train] loss: {} | accuracy: {}'.format(train_loss, train_acc))\n",
    "    print('[Validation] loss: {} | accuracy: {}'.format(val_loss, val_acc))\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if val_acc > max_acc:\n",
    "        patience = 0\n",
    "        max_acc = val_acc\n",
    "        save_path = saver.save(sess, MODEL_PATH)\n",
    "        print(\"Model updated and saved in file: %s\" % save_path)\n",
    "    else:\n",
    "        patience += 1\n",
    "        print('Model not improved at epoch {}/{}. Patience: {}/{}'.format(epoch+1, max_epochs1, patience, max_patience))\n",
    "    # Early stopping.\n",
    "    if patience > max_patience:\n",
    "        print('Max patience exceeded. Early stopping.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss: 0.06079480134104667 | accuracy: 0.5986224170319349\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(sess, loss, correct_prediction, dataset_init_op,\n",
    "                               feed_dict={image_paths: test_image_paths,\n",
    "                                          labels: test_labels,\n",
    "                                          is_training: False})\n",
    "\n",
    "print('[Test] loss: {} | accuracy: {}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     npy_images, npy_labels, _loss, _prediction, _correct_prediction, _accuracy = \\\n",
    "#         sess.run([images, labels, loss, prediction, correct_prediction, accuracy], feed_dict={is_training: False})\n",
    "\n",
    "#     # For plotting\n",
    "#     def _normalize_image(image):\n",
    "#         return (image - image.min()) / (image.max() - image.min())\n",
    "#     images_for_plotting =_normalize_image(_batch_images[0])\n",
    "#     for image in _batch_images[1:]:\n",
    "#         images_for_plotting = np.hstack((images_for_plotting, _normalize_image(image)))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(images_for_plotting)\n",
    "\n",
    "#     print('loss: {}\\nprediction: {}\\nlabels: {}\\ncorrect_prediction: {}\\naccuracy: {}'\\\n",
    "#           .format(_loss, _prediction, npy_labels, _correct_prediction, _accuracy))\n",
    "\n",
    "# except tf.errors.OutOfRangeError:\n",
    "#     print('Batch Iterator becomes empty. Please re-run again.')\n",
    "#     sess.run(val_init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
